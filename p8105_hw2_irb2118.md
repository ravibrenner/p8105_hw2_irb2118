P8105 - HW2
================
Due: 2024-10-02

Author: Ravi Brenner (irb2118)

# Introduction

This Rmarkdown document is for P8105 - Data Science 1, homework 2.

# Methods

The data for this homework comes from the course website, but all files
can be found in the `data/` folder. Additionally, we will be using
packages from the `tidyverse` and `readxl`.

``` r
library(tidyverse)
library(readxl)
```

# Problems

## Problem 1

This problem is about the NYC subway system.

First, we must read in the data, clean up the column names, and select
and transform the columns that we need:

``` r
subway_df <-
  read_csv("data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") |>
  janitor::clean_names() |>
  select(
    line,
    station_name,
    station_latitude,
    station_longitude,
    route1:route11,
    entry,
    vending,
    entrance_type,
    ada
  ) |>
  mutate(entry = case_match(entry,
                            "YES" ~ TRUE,
                            "NO" ~ FALSE))
```

This dataset contains data on each entrance and exit for each subway
line and station (name and geographic location), and the routes that
operate at the line and station (for example, some stops accomodate
multiple trains on the same line, like the NQRW or the 123). There are
additional variables indicating the entrance type, presence of vending
machines, and ADA compliance.

So far, I imported the data using `read_csv`, cleaned up the column
names using `janitor::clean_names`, selected the relevant columns using
`select`, and transformed the `entry` column from character to logical.
After these steps, there are 1868 rows and 19 columns.

There are 465 distinct stations. Of those, 84 are ADA compliant. Of the
station entrances/exits without vending, 69 out of 183 allow entrance,
or 37.7 percent.

Now, I will reformat the data from wide to long, into proper tidy
format:

``` r
subway_df <- subway_df |>
  mutate(across(.cols = route8:route11,
                as.character)) |>
  pivot_longer(cols = route1:route11,
               names_to = "route_number",
               values_to = "route_name",
               names_prefix = "route") |>
  drop_na(route_name)
```

There are 60 distinct stations that serve the A train. Of those, 17 are
ADA compliant.

## Problem 2

First we have to read in and clean the data for Mr. Trash Wheel. Then we
will follow a similar process for Professor Trash Wheel and Gwynnda, and
eventually combine them all into one tidy data set. First, Mr. Trash
Wheel:

``` r
mr_trash_wheel <- read_excel("data/202309 Trash Wheel Collection Data.xlsx",
                             sheet = "Mr. Trash Wheel",
                             range = "A2:N586") |>
  janitor::clean_names() |>
  mutate(sports_balls = as.integer(sports_balls),
         year = as.numeric(year),
         name = "mr_trash_wheel") 
```

And repeat the same process for Professor Trash Wheel and Gwynnda Trash
Wheel:

``` r
prof_trash_wheel <- read_excel("data/202309 Trash Wheel Collection Data.xlsx",
                             sheet = "Professor Trash Wheel",
                             range = "A2:M108") |>
  janitor::clean_names() |>
  mutate(name = "prof_trash_wheel")

gwyn_trash_wheel <- read_excel("data/202309 Trash Wheel Collection Data.xlsx",
                             sheet = "Gwynnda Trash Wheel",
                             range = "A2:L157") |>
  janitor::clean_names() |>
  mutate(name = "gwyn_trash_wheel")
```

Now, combining all the datasets:

``` r
trash_wheels <- bind_rows(mr_trash_wheel,prof_trash_wheel,gwyn_trash_wheel)
```

With these 3 trash wheel datasets combined, there are 845 rows (584 for
Mr. Trash Wheel, 106 for Professor Trash Wheel, and 155 for Gwynnda
Trash Wheel) and 15 columns. Observations range from 1900-01-20 to
2023-06-30. Inspecting the data carefully, that date from 1900 appears
to be an error in the original source excel sheet, not an issue in the
data import process, so it could be worth asking the original data
producer what that date should be. It appears to be a date in January
2020, but it’s unclear which day. The true earliest date in the dataset
is 2014-05-16.

The total weight of trash collected by Professor Trash wheel was 216.26
tons over a period from 2017-01-02 to 2023-06-29.

The total number of cigarette butts collected by Gwynnda in June, 2022
was 18120.

## Problem 3

First, I will import the 3 datasets, and clean up the names in the
process.

``` r
bakers_df <- read_csv("data/bakers.csv") |>
  janitor::clean_names() 

bakes_df <- read_csv("data/bakes.csv") |>
  janitor::clean_names()

results_df <- read_csv("data/results.csv",
                       skip = 2) 
```

`results.csv` already has clean names, but I had to skip the first two
rows which had descriptive data that wasn’t part of the table.

Using `view` and printing the datasets, they look generally complete.
One initial problem I noticed is that the `baker` column in `bakes_df`
and `results_df` uses first name only, while the `bakers_df` uses first
and last name.

Transforming that column in `bakers_df`:

``` r
bakers_df <- bakers_df |>
  mutate(baker = str_split_i(baker_name," ",1))
```

Now I’ll double check for completeness using `anti_join`, on `baker` and
`series` (to ensure that people with same first name aren’t matched).

``` r
anti_join(bakers_df, bakes_df, by = c("baker", "series"))
```

    ## # A tibble: 26 × 6
    ##    baker_name          series baker_age baker_occupation          hometown baker
    ##    <chr>                <dbl>     <dbl> <chr>                     <chr>    <chr>
    ##  1 Alice Fevronia          10        28 Geography teacher         Essex    Alice
    ##  2 Amelia LeBruin          10        24 Fashion designer          Halifax  Amel…
    ##  3 Antony Amourdoux         9        30 Banker                    London   Anto…
    ##  4 Briony Williams          9        33 Full-time parent          Bristol  Brio…
    ##  5 Dan Beasley-Harling      9        36 Full-time parent          London   Dan  
    ##  6 Dan Chambers            10        32 Support worker            Rotherh… Dan  
    ##  7 David Atherton          10        36 International health adv… Whitby   David
    ##  8 Helena Garcia           10        40 Online project manager    Leeds    Hele…
    ##  9 Henry Bird              10        20 Student                   Durham   Henry
    ## 10 Imelda McCarron          9        33 Countryside recreation o… County … Imel…
    ## # ℹ 16 more rows

``` r
anti_join(bakes_df, bakers_df, by = c("baker", "series"))
```

    ## # A tibble: 8 × 5
    ##   series episode baker    signature_bake                            show_stopper
    ##    <dbl>   <dbl> <chr>    <chr>                                     <chr>       
    ## 1      2       1 "\"Jo\"" Chocolate Orange CupcakesOrange and Card… Chocolate a…
    ## 2      2       2 "\"Jo\"" Caramelised Onion, Gruyere and Thyme Qui… Raspberry a…
    ## 3      2       3 "\"Jo\"" Stromboli flavored with Mozzarella, Ham,… Unknown     
    ## 4      2       4 "\"Jo\"" Lavender Biscuits                         Blueberry M…
    ## 5      2       5 "\"Jo\"" Salmon and Asparagus Pie                  Apple and R…
    ## 6      2       6 "\"Jo\"" Rum and Raisin Baked Cheesecake           Limoncello …
    ## 7      2       7 "\"Jo\"" Raspberry & Strawberry Mousse Cake        Pain Aux Ra…
    ## 8      2       8 "\"Jo\"" Raspberry and Blueberry Mille Feuille     Mini Victor…

``` r
anti_join(bakers_df,results_df, by = c("baker","series"))
```

    ## # A tibble: 1 × 6
    ##   baker_name  series baker_age baker_occupation hometown     baker
    ##   <chr>        <dbl>     <dbl> <chr>            <chr>        <chr>
    ## 1 Jo Wheatley      2        41 Housewife        Ongar, Essex Jo

``` r
anti_join(results_df,bakers_df, by = c("baker","series"))
```

    ## # A tibble: 8 × 5
    ##   series episode baker  technical result    
    ##    <dbl>   <dbl> <chr>      <dbl> <chr>     
    ## 1      2       1 Joanne        11 IN        
    ## 2      2       2 Joanne        10 IN        
    ## 3      2       3 Joanne         1 IN        
    ## 4      2       4 Joanne         8 IN        
    ## 5      2       5 Joanne         6 IN        
    ## 6      2       6 Joanne         1 STAR BAKER
    ## 7      2       7 Joanne         3 IN        
    ## 8      2       8 Joanne         1 WINNER

``` r
anti_join(bakes_df,results_df, by = c("baker","series"))
```

    ## # A tibble: 8 × 5
    ##   series episode baker    signature_bake                            show_stopper
    ##    <dbl>   <dbl> <chr>    <chr>                                     <chr>       
    ## 1      2       1 "\"Jo\"" Chocolate Orange CupcakesOrange and Card… Chocolate a…
    ## 2      2       2 "\"Jo\"" Caramelised Onion, Gruyere and Thyme Qui… Raspberry a…
    ## 3      2       3 "\"Jo\"" Stromboli flavored with Mozzarella, Ham,… Unknown     
    ## 4      2       4 "\"Jo\"" Lavender Biscuits                         Blueberry M…
    ## 5      2       5 "\"Jo\"" Salmon and Asparagus Pie                  Apple and R…
    ## 6      2       6 "\"Jo\"" Rum and Raisin Baked Cheesecake           Limoncello …
    ## 7      2       7 "\"Jo\"" Raspberry & Strawberry Mousse Cake        Pain Aux Ra…
    ## 8      2       8 "\"Jo\"" Raspberry and Blueberry Mille Feuille     Mini Victor…

``` r
anti_join(results_df,bakes_df, by = c("baker","series"))
```

    ## # A tibble: 258 × 5
    ##    series episode baker  technical result    
    ##     <dbl>   <dbl> <chr>      <dbl> <chr>     
    ##  1      2       1 Joanne        11 IN        
    ##  2      2       2 Joanne        10 IN        
    ##  3      2       3 Joanne         1 IN        
    ##  4      2       4 Joanne         8 IN        
    ##  5      2       5 Joanne         6 IN        
    ##  6      2       6 Joanne         1 STAR BAKER
    ##  7      2       7 Joanne         3 IN        
    ##  8      2       8 Joanne         1 WINNER    
    ##  9      9       1 Antony        12 IN        
    ## 10      9       1 Briony         2 IN        
    ## # ℹ 248 more rows

Looking at these results, two things jump out:

1.  The baker named “Jo” in series 2 is not matched to a baker in
    `results_df`. Instead there is a baker named “Jo” in `results_df`,
    who appears to be the same person. In `bakes_df` their name is
    stylized as “Jo” with quotation marks, so those need to be fixed
    also.

2.  `bakes_df` does not contain any bakes from series 9 or 10, so all
    the bakers and results from those series are not present.

The first problem is fixable, the second is not; we will have to merge
the data without the bakes from seasons 9 and 10.

Now merging the data:

``` r
gbbo_df <- bakers_df |>
  full_join(bakes_df |>
              mutate(baker = case_when(series == 2 & baker == "\"Jo\"" ~ "Jo",
                                       .default = baker)), 
            by = c("series", "baker")) |>
  full_join(
    results_df |> 
      mutate(baker = case_when(series == 2 & baker == "Joanne" ~ "Jo",
                           .default = baker)) ,
    by = c("series", "baker", "episode")) |>
  arrange(series, episode, baker) |>
  select(series,
         episode,
         baker,      
         result,
         signature_bake,
         technical,
         show_stopper,
         everything())
```

Export to CSV:

``` r
write_csv(gbbo_df,"data/gbbo_data.csv")
```

The final combined dataset has 1161 rows and 11 columns. It is sorted by
series, episode, and baker name, with results in the next column. There
are many missing entries in bakes and results, but this is intentional,
since as players are eliminated they do not return for future weeks, and
there is no data to be populated.

Create a reader-friendly table showing the star baker or winner of each
episode in Seasons 5 through 10. Comment on this table – were there any
predictable overall winners? Any surprises?

Here is a table of star bakers and season winners by season and episode,
from seasons 5-10. Looking at this table, there were some predictable
winners and some surprises. Nancy was a bit of a surprise in season 5,
winning only 1 star baker to Richard’s 5. Nadiya went on a hot streak to
win at the end of season 6. In season 7, Candice was quite consistent
and won several star bakers on the way to victory, similar to Sophie in
season 8. Rahul started strong with 2 star bakers in season 9, but went
through a slump before winning the season. David was perhaps the biggest
dark horse in season 10, not winning a single star baker until his
overall victory in the final episode.

``` r
gbbo_df |>
  filter(series >= 5,
         series <= 10,
         result %in% c("WINNER","STAR BAKER")) |>
  select(series,episode,baker,result) |>
  arrange(series,episode) |>
  knitr::kable()
```

| series | episode | baker     | result     |
|-------:|--------:|:----------|:-----------|
|      5 |       1 | Nancy     | STAR BAKER |
|      5 |       2 | Richard   | STAR BAKER |
|      5 |       3 | Luis      | STAR BAKER |
|      5 |       4 | Richard   | STAR BAKER |
|      5 |       5 | Kate      | STAR BAKER |
|      5 |       6 | Chetna    | STAR BAKER |
|      5 |       7 | Richard   | STAR BAKER |
|      5 |       8 | Richard   | STAR BAKER |
|      5 |       9 | Richard   | STAR BAKER |
|      5 |      10 | Nancy     | WINNER     |
|      6 |       1 | Marie     | STAR BAKER |
|      6 |       2 | Ian       | STAR BAKER |
|      6 |       3 | Ian       | STAR BAKER |
|      6 |       4 | Ian       | STAR BAKER |
|      6 |       5 | Nadiya    | STAR BAKER |
|      6 |       6 | Mat       | STAR BAKER |
|      6 |       7 | Tamal     | STAR BAKER |
|      6 |       8 | Nadiya    | STAR BAKER |
|      6 |       9 | Nadiya    | STAR BAKER |
|      6 |      10 | Nadiya    | WINNER     |
|      7 |       1 | Jane      | STAR BAKER |
|      7 |       2 | Candice   | STAR BAKER |
|      7 |       3 | Tom       | STAR BAKER |
|      7 |       4 | Benjamina | STAR BAKER |
|      7 |       5 | Candice   | STAR BAKER |
|      7 |       6 | Tom       | STAR BAKER |
|      7 |       7 | Andrew    | STAR BAKER |
|      7 |       8 | Candice   | STAR BAKER |
|      7 |       9 | Andrew    | STAR BAKER |
|      7 |      10 | Candice   | WINNER     |
|      8 |       1 | Steven    | STAR BAKER |
|      8 |       2 | Steven    | STAR BAKER |
|      8 |       3 | Julia     | STAR BAKER |
|      8 |       4 | Kate      | STAR BAKER |
|      8 |       5 | Sophie    | STAR BAKER |
|      8 |       6 | Liam      | STAR BAKER |
|      8 |       7 | Steven    | STAR BAKER |
|      8 |       8 | Stacey    | STAR BAKER |
|      8 |       9 | Sophie    | STAR BAKER |
|      8 |      10 | Sophie    | WINNER     |
|      9 |       1 | Manon     | STAR BAKER |
|      9 |       2 | Rahul     | STAR BAKER |
|      9 |       3 | Rahul     | STAR BAKER |
|      9 |       4 | Dan       | STAR BAKER |
|      9 |       5 | Kim-Joy   | STAR BAKER |
|      9 |       6 | Briony    | STAR BAKER |
|      9 |       7 | Kim-Joy   | STAR BAKER |
|      9 |       8 | Ruby      | STAR BAKER |
|      9 |       9 | Ruby      | STAR BAKER |
|      9 |      10 | Rahul     | WINNER     |
|     10 |       1 | Michelle  | STAR BAKER |
|     10 |       2 | Alice     | STAR BAKER |
|     10 |       3 | Michael   | STAR BAKER |
|     10 |       4 | Steph     | STAR BAKER |
|     10 |       5 | Steph     | STAR BAKER |
|     10 |       6 | Steph     | STAR BAKER |
|     10 |       7 | Henry     | STAR BAKER |
|     10 |       8 | Steph     | STAR BAKER |
|     10 |       9 | Alice     | STAR BAKER |
|     10 |      10 | David     | WINNER     |

Now, I will look at the viewership data. After importing and cleaning
the column names, I pivot the data from wide to long, and reorder and
arrange the columns for easier viewing.

``` r
viewers_df <- read_csv("data/viewers.csv") |>
  janitor::clean_names() |>
  pivot_longer(cols = series_1:series_10,
               names_to = "series",
               values_to = "viewers",
               names_prefix = "series_") |>
  mutate(series = as.numeric(series)) |>
  select(series,everything()) |>
  arrange(series,episode)
```

Here are the first few rows of the dataset:

``` r
viewers_df |>
  head(n = 10) |>
  knitr::kable()
```

| series | episode | viewers |
|-------:|--------:|--------:|
|      1 |       1 |    2.24 |
|      1 |       2 |    3.00 |
|      1 |       3 |    3.00 |
|      1 |       4 |    2.60 |
|      1 |       5 |    3.03 |
|      1 |       6 |    2.75 |
|      1 |       7 |      NA |
|      1 |       8 |      NA |
|      1 |       9 |      NA |
|      1 |      10 |      NA |

The average viewership was 2.77 in season 1 and 10.0393 in season 5
(excluding episodes with missing viewership data). Although no
explicitly stated, these viewership numbers likely represent either some
multiple of viewers (i.e., time 1,000,000), or some other TV rating
scale that may take live and streaming viewership into account. In
either case, the viewership in season 5 is much larger than that of
season 1.

# Conclusion

This homeworks assignment showcased various techniques related to
importing, cleaning, tidying, and manipulating data using R and
Rmarkdown.
